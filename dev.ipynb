{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2fcb6a35",
   "metadata": {},
   "source": [
    "# TODO: Review commented out parameters in lvae TopDownLayer and reimplement\n",
    "1) TODO when we meet in person: Review if I implemented head_z_dims correctly (done)\n",
    "2) Unknown params:\n",
    "- use_mode (never used?) # ok to remove. -> depends on mode_layers # remove also this (it's for sampling that we don't need)\n",
    "- force_constant_output (never used?) # dunno (removed)\n",
    "- difference between use_uncond_mode and inference_mode?\n",
    "    - in TopDownLayer.forward the merge layer is commented out, so use_uncond_mode is uneffective. Why? Does it matter?\n",
    "        - TODO: YES. This is one of the parts to ablate. It is currently disabled because it lead to better results, we need to make it switchable for-layer.\n",
    "          - there is self.use_uncond_mode_at that can be used for this.\n",
    "        - This has been renamed to use_skip_connections (done)\n",
    "3) There are A LOT of places when the networks are on the wrong device.\n",
    "    - Should be fixed (done)\n",
    "4) Do we need to ablate bu_values or skip_connections in TopDownLayer?\n",
    "    - both\n",
    "5) Check if the KL handling in inference is correct (MixtureStochasticConvBlock.forward when label is None) (done)\n",
    "\n",
    "- Entropy should be removed (done)\n",
    "- \"pi\" became \"class_probabilities\" (done)\n",
    "\n",
    "\n",
    "-  !!!! Threshold: Should be added as a scheduler and decrease donly in semisupervised mode (see trainer.py line 284 in Sheida's repo)\n",
    "\n",
    "- \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb7981e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from eps_seg.config import LVAEConfig\n",
    "import torch\n",
    "\n",
    "config = LVAEConfig()\n",
    "print(config)\n",
    "\n",
    "from eps_seg.modules.lvae import LadderVAE\n",
    "x = torch.randn(2, 1, 64, 64)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "x = x.to(device)\n",
    "model = LadderVAE(config, \n",
    "                  device=\"cuda\", \n",
    "                  data_mean=0., \n",
    "                  data_std=1.,\n",
    "                  mode_pred=True).to(device)\n",
    "                  \n",
    "\n",
    "model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce37db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inference mode: We mean that we have an input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b540f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Import torchvista\n",
    "from torchvista import trace_model\n",
    "\n",
    "# Trace!\n",
    "trace_model(model, x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eps-Seg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
